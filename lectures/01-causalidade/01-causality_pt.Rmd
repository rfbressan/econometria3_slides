---
title: "Econometria III"
subtitle: "Introdução a Causalidade"
author: "Rafael Bressan"
date: "Esag </br> `r Sys.Date()`"
output:
  xaringan::moon_reader:
    chakra: "https://cdnjs.cloudflare.com/ajax/libs/remark/0.14.0/remark.min.js"
    lib_dir: libs
    css: [default, "../../css/scpo.css", "../../css/scpo-fonts.css"]
    nature:
      beforeInit: ["../../js/ru_xaringan.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    includes:
      in_header: "../../libs/partials/header.html"
---

layout: true

<div class="my-footer"><img src="../../img/logo/UdescEsag.jpeg" style="height: 60px;"/></div> 

---

```{r setup, include=FALSE,warning=FALSE,message=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  dev = "svg",
  cache = TRUE,
  fig.align = "center"
  #fig.width = 11,
  #fig.height = 5
)

# define vars
om = par("mar")
lowtop = c(om[1],om[2],0.1,om[4])

overwrite = FALSE

library(tidyverse)
library(ggplot2)
library(emo)
library(dplyr)
# library(png)
library(grid)
library(pander)
# library(countdown)

# countdown style
# countdown(
#   color_border              = "#d90502",
#   color_text                = "black",
#   color_running_background  = "#d90502",
#   color_running_text        = "white",
#   color_finished_background = "white",
#   color_finished_text       = "#d90502",
#   color_finished_border     = "#d90502"
# )
```

layout: true

<div class="my-footer"><img src="../../img/logo/UdescEsag.jpeg" style="height: 60px;"/></div> 

---

# Introdução a Inferência Causal

* ***Causalidade*** versus ***Correlação***

* _Framework_ de ***Resultados Potenciais*** a.k.a. Modelo Causal de Rubin

* ***Experimentos Aleatorizados*** (Randomized Controlled Trials - RCTs)

* Aplicação empírica. *Tamanho de turma* e *performance do estudante*

---
# Por que Estudar Causalidade?

[![](../../img/photos/the_economist.png)](https://www.economist.com/business/2022/09/07/why-economists-are-flocking-to-silicon-valley)


---
# Por que Estudar Causalidade?

[![](../../img/photos/hbr_economics.png)](https://hbr.org/2019/02/why-tech-companies-hire-so-many-economists)

---

# Causalidade e Economia

- Fazer inferência causal a partir de dados pode ser visto como a **vantagem comparativa** dos economistas!

- Diversos campos fazem estatística. Mas poucos treinam seus estudantes para compreender causalidade.

- Conhecimento de inferência causal é o que torna economistas úteis tanto no setor privado (e.g. empresas de tecnologia) e setor público (e.g. avaliação de políticas públicas)

--

- Ok, chega de pregar causalidade. `r emo::ji("sweat_smile")`


---

# O Conceito de Causalidade

__Causalidade__: do que estamos falando? 

- Dizemos que `X` *causa* `Y`

--

  - se nós **intervirmos** no valor de `X` ***sem mudar nada a mais*** ...
  
--

  - então `Y` também mudará ***como resultado***.
  
--

- O ponto pricipal é ***sem mudar nada a mais***, também referido por **ceteris paribus (*tudo o mais constante*)**.

--

- `r emo::ji("warning")` Isto ***NÃO*** significa que `X` é o único fator que causa `Y`.

---

# Correlação vs Causalidade

***Correlação não é o mesmo que causalidade*** tornou-se um mantra, mas você consegue dizer porquê?

--

Algumas correlações são obviamente espúrias e não tem nada a ver com causa e efeito ([e.g. spurious correlation website](https://www.tylervigen.com/spurious-correlations)).

--

```{r, echo = FALSE, out.width = "800px"}
knitr::include_graphics("../../img/photos/spurious.png")
```

---

# Correlação vs Causalidade: Fumar e Câncer de Pulmão

Mas nem todas as correlações são fáceis de diferenciar

--

***Fumar causa câncer de pulmão?***

--

.pull-left[
- Hoje em dia, nós sabemos que a resposta é *SIM*! 

- Mas, voltemos para 1950

  - Início de um grande aumento no número de mortes por câncer de pulmão...
  
  - ... que ocorre após um rápido aumento no consumo de cigarros
]

--

.pull-right[
```{r, echo = FALSE, out.width = "400px"}
knitr::include_graphics("../../img/photos/Smoking_lung_cancer.png")
```
]

--

- É tentador argumentar que fumar cigarros **causa** câncer de pulmão baseado neste gráfico.

---

# Correlação vs Causalidade: Fumar e Câncer de Pulmão

Na época, muitos eram céticos a esta hipótese, incluindo famosos estatísticos.

--

.pull-left[
***Macro fatores de confusão***:  

Outros fatores macro que podem causar câncer também mudaram entre  1900 e 1950:

  - Asfaltamento de estradas,
  
  - Inalação de fumaça de motores (vapores de gasolina com chumbo),
  
  - Maior poluição atmosférica geral.
]

--

.pull-right[
***Auto seleção***:

Fumantes e não fumantes podem ser diferentes em primeiro lugar:
  
   - _Seleção de características observáveis_: idade, escolaridade, renda, etc.
  
   - _Seleção de características não observáveis_: genes (a hipotética teoria do genoma de [Fisher](https://en.wikipedia.org/wiki/Ronald_Aylmer_Fisher)). 
]

---

# Correlação vs Causalidade: Outros Exemplos

> Por que a correlação observada entre ***anos de estudo*** e ***renda*** não reflete o efeito causal da educação?

--

*Indivíduos que optam por obter mais educação provavelmente diferem daqueles que não: talvez tenham maior habilidade inata, gostem de estudar e sejam bons nisso* $\rightarrow$ ***autosseleção***

--

> ***Taxa de emprego*** e o nível do ***salário mínimo*** não reflete o efeito causal do salário mínimo?

--

*Aumento de salário mínimo em momentos em que a taxa de emprego é alta* $\rightarrow$ ***causalidade reversa / simultaneidade***

--

> ***Crescimento econômico*** e ***desenvolvimento financeiro*** não reflete o efeito causal do setor financeiro?

--

*Talvez crescimento econômico leve ao desenvolvimento financeiro e não o contrário* $\rightarrow$ ***causalidade reversa / simultaneidade***

---

# Link com a Teoria Econômica

* A teoria econômica nos diz que os indivíduos se comportam para ***maximizar sua utilidade***

* Assim, eles não escolhem agir de ***forma aleatória*** $\rightarrow$ dizemos que o comportamento do indivíduo é ***endógeno***

* Devemos ser ***suspeitos*** de qualquer correlação encontrada nos dados

--

- Como podemos fazer ***reivindicações causais*** então?

- O framework de ***Resultados Potenciais*** será o nosso guia.

---
layout: false
class: title-slide-section-red, middle

# Inferência Causal

---
layout: true

<div class="my-footer"><img src="../../img/logo/UdescEsag.jpeg" style="height: 60px;"/></div> 

---

# O framework de Resultados Potenciais

Frequentemente chamado de **Modelo Causal de Rubin** em homenagem ao estatístico **Donald Rubin**, que generalizou e formalizou esse modelo na década de 1970.

--

***Idéia-chave***: Cada indivíduo pode ser exposto a **vários estados alternativos de tratamento**.
   - fumar cigarros, fumar charutos ou não fumar,
   - crescendo em um bairro pobre versus um bairro de classe média versus um bairro rico,
   - estar em uma turma pequena ou grande.
  
--

.pull-left[
Por praticidade, deixe esta variável de tratamento $D_i$ ser uma variável binária:

$$
D_i = \begin{cases} 
                    1 \textrm{ se indivíduo $i$ é tratado} \\\\ 
                    0 \textrm{ se indivíduo $i$ não é tratado} 
      \end{cases}
$$
]

--

.pull-right[

***Grupo de tratamento***
todos os indivíduos tais que $D_i = 1$.

***Grupo de controle***
todos os indivíduos tais que $D_i = 0$.
]

---


# O framework de Resultados Potenciais

* Nessa estrutura, cada indivíduo tem dois ***resultados potenciais***, mas apenas um ***resultado observado*** $Y_i$:
  
   - $Y_i^1$: *resultado potencial se o indivíduo $i$ receber o tratamento*,
  
   - $Y_i^0$: *resultado potencial se o indivíduo $i$ não receber o tratamento*.

--

* Na vida real, observamos apenas $Y_i$ que pode ser escrito como:

$$Y_i = D_i \times Y_i^1 + (1- D_i) \times Y_i^0$$

--

* ***Problema fundamental da inferência causal***: para qualquer indivíduo $i$, observamos apenas um dos resultados potenciais [(Holland, 1986)](http://people.umass.edu/~stanek/pdffiles /causal-holland.pdf).
---

# O framework de Resultados Potenciais

* O resultado potencial que não é observado existe em princípio, é chamado de ***resultado contrafactual***.

--

Grupo | $Y_i^1$ | $Y_i^0$
--------|:---------:|:---------:
Tratamento $(D_i = 1)$ &nbsp; &nbsp; | &nbsp; &nbsp; Observável como $Y_i$ &nbsp; &nbsp; | Contrafactual
Controle $(D_i = 0)$ | Contrafactual | &nbsp; &nbsp; Observável como $Y_i$ &nbsp; &nbsp;

--

* A partir deles podemos definir o ***efeito de tratamento individual*** $\delta_i= Y_i^1 - Y_i^0$

* $\delta_i$ mede o **efeito causal do tratamento** $D_i$ no resultado $Y_i$ do indivíduo

--

* O efeito do tratamento ***não*** pode ser observado no nível individual (Por quê?), nossos estimandos serão médias populacionais.
---

name: ate

# Efeito Médio do Tratamento (ATE)

Efeito médio mais amplo possível:

\begin{align}
ATE &= \mathop{\mathbb{E}}(\delta_i) \\
     &= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0) \\
     &= \mathop{\mathbb{E}}(Y_i^1) - \mathop{\mathbb{E}}(Y_i^0)
\end{align}
  
* O ATE mede simplesmente a ***média dos efeitos individuais do tratamento sobre toda a população***.

([*Apêndice:*](#attandatu) Tratamento Médio nos Tratados e Tratamento Médio nos Não Tratados)
---

# Exemplo: Classe Pequena vs. Grande

Resultados potenciais para os alunos em turma pequena $(Y^1)$ ou grande $(Y^0)$:

.pull-left[
Aluno | &nbsp; &nbsp; $Y^1$ &nbsp; &nbsp; | &nbsp; &nbsp; $Y^0$ &nbsp; &nbsp; | &nbsp; &nbsp; $\delta$ &nbsp; &nbsp;
-----------|:---------:|:------:|:---------:|
1 | 5 | 2 | 3
2 | 6 | 4 | 2
3 | 3 | 6 | -3
4 | 5 | 4 | 1
5 | 10 | 8 | 2
6 | 2 | 4 | -2
7 | 5 | 2 | 3
8 | 6 | 4 | 2
Média | 5.25 | 4.25 | 1.0

]

--

.pull-right[

$$
\begin{align}
\color{#d90502}{\text{ATE}} &= \mathbb{E}(\delta) \\
&=\mathbb{E}(Y^1) - \mathbb{E}(Y^0) \\
&= 5.25 - 4.25 \\
&= 1.0
\end{align}
$$

- o efeito causal ***médio*** de estar na turma pequena em relação à grande nas notas é de 1 ponto.

- `r emo::ji("warning")` nem todos os alunos se beneficiaram igualmente com o tratamento!

]
---

# O problema da Inferência Causal

* Na prática, temos o mesmo **problema de falta de dados** para calcular o ATE que tivemos para $\delta_i$. Falta $Y_i^1$ ou $Y_i^0$ para cada $i$.

--

* A partir dos dados, podemos calcular a **D**iferença **S**imples nas médias dos **R**esultados (***DSR***) para ambos os grupos:

$$
\begin{align}
DSR &= \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) \\
&= \underbrace{\frac{1}{N_T}\sum_{i=1}^{N_T}(Y_i|D_i=1)}_{\text{resultado médio do grupo de tratamento}} - \underbrace{\frac {1}{N_C}\sum_{i=1}^{N_C}(Y_i|D_i=0)}_{\text{resultado médio do grupo de controle}}
\end{align}
$$

---

# Diferença Simples nas médias dos Resultados: um exemplo

.pull-left[
Estudante | &nbsp; &nbsp; $Y$ &nbsp; &nbsp; | &nbsp; &nbsp; $D$ &nbsp; &nbsp; | &nbsp; &nbsp; $\delta$&nbsp; &nbsp;
-----------|:---------:|:---------:|:---------:
1 | 5 | 1 | 3
2 | 6 | 1 | 2
3 | 6 | 0 | -3
4 | 4 | 0 | 1
5 | 10 | 1 | 2
6 | 4 | 0 | -2
7 | 5 | 1 | 3
8 | 6 | 1 | 2

]

.pull-right[
A diferença simples na média dos resultados:

$$
\begin{align}
DSR &= \frac{5+6+10+5+6}{5} - \frac{6+4+4}{3} \\
&\approx 6.4 - 4.67 \approx 1.73
\end{align}
$$

* A DSR é bem maior que o ATE!

* A DSR **irá (quase sempre) falhar em capturar o efeito causal do tratamento**

* Observe que esse tipo de comparação "ingênua" é frequentemente feita por jornalistas, políticos, cientistas mal treinados (mas você não mais! `r emo::ji("wink")`)
]

---

name: naive_comp

# Problemas com comparações ingênuas

Reescrever a DSR para fazer o efeito de tratamento individual $(\delta_i)$ aparecer na equação.

$$
\begin{align}
   DSR &= \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) \\ &= \mathop{\mathbb{ E}}(Y_i^0 + \delta_i | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)
\end{align}
$$
--

Para simplificar, suponha que o **efeito do tratamento seja constante** entre as pessoas: para todo $i, \delta_i = \delta$.

--

$$DSR = \delta + \underbrace{\mathop{\mathbb{E}}(Y_i^0 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)}_\text{Viés de Seleção}$$

E por hipótese: $ATE = \mathop{\mathbb{E}}(\delta_i) = \mathop{\mathbb{E}}(\delta) = \delta$ 


([*Apêndice*](#naive_comp_extended): quando a suposição de tratamento constante é relaxada, outro termo de viés aparece.)
---

# Aleatorização resolve o problema da inferência causal!

* ***Experimentos aleatorizados***: você atribui ***aleatoriamente*** pessoas a um tratamento e a um grupo de controle.

* Nesse caso, a atribuição do tratamento é **independente** dos resultados potenciais. 

--

* Em particular, não há razão para $\mathop{\mathbb{E}}(Y_i^0 | D_i = 1)$ ser diferente de $\mathop{\mathbb{E}}(Y_i^0 | D_i = 0)$

   * Portanto, o ***viés de seleção é igual a 0***.

--

* Com atribuição aleatória, temos:

$$ DSR = \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) = ATE$$

`r emo::ji("point_right")` Podemos estimar o ATE diretamente a partir dos dados!
---

layout: false
class: title-slide-section-red, middle

# Experimentos Aleatorizados

---
layout: true

<div class="my-footer"><img src="../../img/logo/UdescEsag.jpeg" style="height: 60px;"/></div> 

---

# Experimentos Aleatorizados

- Frequentemente chamados de **R**andomized **C**ontrolled **T**rials (RCT).

- Os primeiros RCTs foram realizados há muito tempo (séculos XVIII e XIX), principalmente em **Medicina**.

- No início do século XX foram popularizados por estatísticos famosos como **J. Neyman** ou **R.A. Fisher**.

- Desde então, eles tiveram uma influência crescente e se tornaram progressivamente uma confiável [ferramenta para avaliação de políticas públicas](https://www.povertyactionlab.org/fr).

- Quanto à economia, o **Prêmio Nobel de Economia de 2019** foi concedido a três expoentes dos RCTs, [Abhijit Banerjee, Esther Duflo e Michael Kremer](https://www.economist.com/finance-and-economics/ 2019/10/17/a-nobel-economics-prêmio-vai-para-pioneiros-na-compreensão-da-pobreza), "por sua abordagem experimental para aliviar a pobreza global".
---

# Tamanho da turma e desempenho dos alunos

Suponha que regredimos as notas médias dos alunos em matemática ou leitura no tamanho da turma.

$$\textrm{matemática}_i = b_0 + b_1 \textrm{tamanho}_i + e_i$$

Sem maiores informações sobre a origem dos dados coletados, $b_1^{OLS}$ só poderá estabelecer uma ***associação*** e não uma ***relação causal***.

--

* **Seleção de alunos**: seleção em escolas com turmas de tamanhos diferentes. Pais tenham a noção de que turmas menores são melhores, eles colocarão seus filhos nessas escolas.

--

* **Seleção de professores**: os professores escolhem escolas com turmas menores porque é mais fácil ensinar nestas e, se houver competição, os professores melhores terão as vagas.

--

Um RCT cuidaria de todos esses vieses!
---

# O Experimento do Projeto STAR

Tennessee **S**student/**T**eacher **A**chievement **R**atio Experiment (ver [Krueger (1999)](http://piketty.pse.ens.fr/files/Krueger1999.pdf))

* Financiado pela legislatura do Tennesse por um custo total de aprox. $ 12 milhões.

* A experiência começou no ano letivo de 1985-1986 e durou quatro anos.

--

* 11.600 alunos e professores foram **distribuídos aleatoriamente** para um dos 3 grupos a seguir, do jardim de infância até a terceira série:

   1. ***Turma pequena***: 13-17 alunos por professor,
  
   2. ***Aula regular***: 22-25 alunos,
  
   3. ***Classe regular/auxiliar***: 22-25 alunos com um *auxiliar* do professor em tempo integral.

---
# O Experimento do Projeto STAR

* A aleatorização ocorreu dentro das escolas.

* As habilidades de matemática e leitura dos alunos foram testadas por volta de março de cada ano.

--

* Houve um problema de ***atrito não aleatório***, mas vamos ignorá-lo.

---

class:inverse

# Tarefa: Dados STAR (usando R)

1. Carregue os dados *STAR*  [daqui](https://www.dropbox.com/s/bf1fog8yasw3wjj/star_data.csv?dl=1) e atribua-os a um objeto chamado `star_df`. Leia a ajuda para os dados [aqui](https://rdrr.io/cran/AER/man/STAR.html) para entender a que correspondem as variáveis. (Observação: os dados foram *reformulados*, portanto, não se preocupe com o "k", "1" etc. nos nomes das variáveis na ajuda.)

1. Qual é a unidade de observação? Qual variável contém: (i) a designação (aleatória) da turma, (ii) a nota do aluno na turma, (iii) os resultados de interesse?

1. Quantas observações existem? Por que tantas se 11.598 alunos participaram? Por que existem tantos 'NA's? A que eles correspondem?

1. Mantenha apenas os casos sem `NA`s com o seguinte código:
`star_df <- star_df[complete.cases(star_df),]`

1. Vamos verificar o quão bem a aleatorização foi feita fazendo ***verificações de balanceamento***.
Calcule a porcentagem média de meninas, afro-americanos e alunos com almoço gratuito por série *e* classe de tratamento. 

---
# Tarefa: Dados STAR (usando R)

```{r, echo = TRUE}
star_df = readr::read_csv(file = "https://www.dropbox.com/s/bf1fog8yasw3wjj/star_data.csv?dl=1")
star_df <- star_df[complete.cases(star_df),]

star_df |> 
    group_by(grade, star) |> 
    summarise(girls = sum(gender == "female")/n())
```

---

# O Experimento do Projeto STAR

Acabamos de ver que em um RCT o Efeito Médio do Tratamento é obtido computando as diferenças nos resultados entre os grupos de tratamento e controle.

Vamos nos concentrar apenas em:

- Um grupo de tratamento: **pequenas turmas**,

- Um grupo de controle: **aulas regulares**,

- Uma série: **jardim de infância** (k).
--

```{r, echo = FALSE}
diff_table = data.frame(
    grade = rep(c("1","2","3","k"), each = 2),
    test = rep(c("math","read"), times = 4),
    star_df  %>%
        pivot_longer(cols = c("math","read"), names_to = "test", values_to = "score") %>%
        filter(star == "regular") %>%
        group_by(grade, test) %>%
        summarise(mean_regular = round(mean(score), 3)) %>%
        ungroup() %>%
        select(mean_regular),
    star_df %>%
        pivot_longer(cols = c("math","read"), names_to = "test", values_to = "score") %>%
        filter(star == "small") %>% group_by(grade, test) %>%
        summarise(mean_small = round(mean(score), 3)) %>%
        ungroup() %>%
        select(mean_small),
    star_df %>%
        pivot_longer(cols = c("math","read"), names_to = "test", values_to = "score") %>%
        filter(star == "regular+aide") %>%
        group_by(grade, test) %>%
        summarise(mean_regular_aide = round(mean(score), 3)) %>%
        ungroup() %>%
        select(mean_regular_aide)) %>%
    mutate(
        diff_small_regular = round(mean_small - mean_regular, 3),
        diff_regular_aide_regular = round(mean_regular_aide - mean_regular, 3)
    ) %>%
    arrange(factor(grade, levels = c("k","1","2","3")))
```

série | teste | média regular | média pequena | ATE
--------|---------|:---------:|:---------:|:---------:
k | matemática | `r round(diff_table[1,3], 2)` | `r round(diff_table[1,4], 2)` | `r round(diff_table[1,4] - diff_table[1,3], 2)`
k | leitura | `r round(diff_table[2,3], 2)` | `r round(diff_table[2,4], 2)` | `r round(diff_table[2,4] - diff_table[2,3], 2)`

Qual é a interpretação para esses ATEs?

---

# RCT em forma de Regressão

$$ Y_i = D_i Y_i^1 + (1 - D_i) Y_i^0 $$

--

Fatorando por $D_i$ e substituindo $Y_i^1 - Y_i^0$ por $\delta_i$, obtemos:

$$\begin{align} Y_i &=Y_i^0 +D_i (Y_i^1 - Y_i^0) \\ &= Y_i^0 +D_i \delta_i \end{align}$$

--

Assumindo $\delta_i = \delta$, para todo $i$, então $Y_i = Y_i^0 + D_i \delta$

--

Adicionando $\mathbb{E}[Y_i^0] - \mathbb{E}[Y_i^0] = 0$ ao lado direito:

$$\begin{align} Y_i &= \mathbb{E}[Y_i^0] + D_i \delta + Y_i^0 - \mathbb{E}[Y_i^0] \\ &= b_0 + \delta D_i + e_i \end{align}$$
onde $b_0 = \mathbb{E}[Y_i^0]$ e $e_i = Y_i^0 - \mathbb{E}[Y_i^0]$

---

# O Experimento do Projeto STAR: Regressão

A última equação se parece exatamente com o modelo de regressão simples! (com $\delta = b_1$)

Vamos, portanto, estimar o ATE de ser designado para uma turma pequena em notas de matemática.

--

Queremos estimar o seguinte modelo: $\text{math score}_i = b_0 + \delta \text{small}_i + e_i$, com

$$
\text{pequeno}_i = \begin{cases}
                     1 \textrm{ se atribuído a uma turma pequena} \\\\
                     0 \textrm{ se atribuído a uma turma regular}
       \end{cases}
$$
.pull-left[
```{r, echo = TRUE}
star_df_k_small <- star_df %>%
    filter(star %in% c("regular", "small") &
           grade == "k") %>% 
  mutate(small = (star == "small"))
```

]

.pull-left[
```{r, echo = TRUE}
star_df_k_small %>%
  count(star, grade)
```
]

---

# O Experimento do Projeto STAR: Regressão

Modelo de regressão que queremos estimar: $\text{math score}_i = b_0 + \delta \text{small}_i + e_i$

```{r, eco = TRUE, eval = TRUE}
lm(math ~ small, star_df_k_small)
```

--

Lembre-se de que: $b_0 = \mathbb{E}[Y_i^0]$ e $\delta = \mathbb{E}[Y_i | D_i = 1] - \mathbb{E}[Y_i | D_i = 0]$

.pull-left[
```{r}
b_0 = mean(star_df_k_small$math[
    star_df_k_small$small == FALSE])
b_0
```
]

.pull-right[
```{r}
delta = mean(star_df_k_small$math[
    star_df_k_small$small == TRUE]) - 
  mean(star_df_k_small$math[
    star_df_k_small$small == FALSE])
delta
```
]

---

# Regressão com uma Variável Dummy: Graficamente

O regressor em nossa regressão é uma ***variável binária***, ou seja, uma variável que assume os valores VERDADEIRO ou FALSO (1 ou 0).

```{r, echo = F, fig.height=4.75, fig.width = 8}
baseline_graph <- star_df_k_small %>%
    mutate(small = ifelse(small == "TRUE",1,0)) %>%
    ggplot(aes(x = small, y = math)) +
    geom_count(alpha = .7) +
    labs(x = "Atribuído a uma turma pequena", y = "Nota Matemática", 
         size = "Número estudantes") +
    scale_x_continuous(lim = c(-.5,1.5), breaks = c(0,1), labels = c("0\nFALSE","1\nTRUE")) +
    theme_bw(base_size = 20) +
    theme(legend.position = c(0,1),
          legend.justification = c(0,1),
          legend.background = element_blank(),
          legend.key=element_blank(),
          legend.text = element_text(size = 12),
          legend.title = element_text(size = 12, face = "italic")) 
baseline_graph
```

---

# Regressão com uma Variável Dummy: Graficamente

O regressor em nossa regressão é uma ***variável binária***, ou seja, uma variável que assume os valores VERDADEIRO ou FALSO (1 ou 0).

```{r, echo = F, fig.height=4.75, fig.width = 8}
baseline_graph_mean = baseline_graph + 
    stat_summary(fun = mean, colour = c("#d90502","#DE9854"), size = .75, alpha = 0.9) +
    annotate("text", x = 0.04, y = b_0 - 12, hjust = 0, label = "E(Y | small = 0)", size = 5, colour = "#d90502") +
    annotate("text", x = 0.04 + 1, y = b_0 + delta + 16, hjust = 0, label = "E(Y | small = 1)", size = 5, colour = "#DE9854")
baseline_graph_mean
```

---

# Regressão com uma Variável Dummy: Graficamente

O regressor em nossa regressão é uma ***variável binária***, ou seja, uma variável que assume os valores VERDADEIRO ou FALSO (1 ou 0).

```{r, echo = F, fig.height=4.75, fig.width = 9}
baseline_graph_mean + 
    geom_abline(slope = delta, intercept = b_0) +
    geom_curve(aes(x = -0.3, xend = -0.2, 
                   y = 425 , yend = b_0 - .5*delta - 5), 
               size = .5, linetype = 1, colour = "black", 
               arrow = arrow(length = unit(0.3, "cm"))) +
    annotate("text", x = -0.5, y = 415, hjust = 0, 
             label = "Reta de Regressão", size = 5)
```


---

# Regressão com uma Variável Dummy: Graficamente

O regressor em nossa regressão é uma ***variável binária***, ou seja, uma variável que assume os valores VERDADEIRO ou FALSO (1 ou 0).

```{r, echo = FALSE, fig.height=4.75, fig.width = 8}
star_df_k_small %>%
    mutate(small = ifelse(small == "TRUE",1,0)) %>%
    filter(math >= 475 & math <= 500) %>%
    ggplot(aes(x = small, y = math)) +
    geom_segment(aes(x = 0, xend = 1.25, y = b_0, yend = b_0), 
                 size = .5, linetype = 2, colour = "grey") +
    geom_segment(aes(x = 1, xend = 1.25, y = b_0 + delta, yend = b_0 + delta),
                 size = .5, linetype = 2, colour = "grey") +
    geom_count(alpha = .7) +
    stat_summary(data = star_df_k_small %>%
                     mutate(small = ifelse(small == "TRUE",1,0)), 
                 fun = mean, colour = c("#d90502","#DE9854"), 
                 size = .75, alpha = 0.9) +
    geom_abline(slope = delta, intercept = b_0) +
    geom_segment(aes(x = 1.25, xend = 1.25, y = b_0, yend = b_0 + delta), 
                 size = .5, linetype = 1, colour = "black", 
                 arrow = arrow(length = unit(0.3, "cm"), ends = "both")) +
    annotate("text", x = 0.06, y = b_0 - 1, hjust = 0, 
             label = "E(Y | small = 0)", col = "#d90502", size = 5) +
    annotate("text", x = 0.5, y = b_0 + delta + .5, hjust = 0, 
             label = "E(Y | small = 1)", col = "#DE9854", size = 5) +
    annotate("text", x = 1.28, y = b_0 + (delta/2), hjust = 0, parse = TRUE,
             label = "delta", col = "black", size = 8) +
    labs(x = "Atribuído a uma turma pequena", y = "Nota Matemática", 
         size = "Número estudantes") +
    scale_x_continuous(lim = c(-.5,1.5), breaks = c(0,1), 
                       labels = c("0\nFALSE","1\nTRUE")) +
    theme_bw(base_size = 20) +
    theme(legend.position = c(0,1),
          legend.justification = c(0,1),
          legend.background = element_blank(),
          legend.key=element_blank(),
          legend.text = element_text(size = 12),
          legend.title = element_text(size = 12, face = "italic"))
```

---

# Regressão com uma Variável Dummy: Formalmente

Lembre-se do modelo de regressão: $\text{math score}_i = b_0 + \delta \text{small}_i + e_i$

$\begin{align} \mathbb{E}[\textrm{math score} | \text{small}_i = 0]&= \mathbb{E}[b_0 + \delta \text{small}_i + e_i | \text{small}_i = 0] \\ &= b_0 + \delta \mathbb{E}[\text{small}_i| \text{small}_i = 0] + \mathbb{E}[e_i|\text{small}_i = 0] \\ &= b_0 \end{align}$

--

$\begin{align} \mathbb{E}[\textrm{math score} | \text{small}_i = 1]&= \mathbb{E}[b_0 + \delta \text{small}_i + e_i | \text{small}_i = 1] \\ &= b_0 + \delta \mathbb{E}[\text{small}_i| \text{small}_i = 1] + \mathbb{E}[e_i|\text{small}_i = 1] \\ &= b_0 + \delta \end{align}$

--

$\begin{align} ATE &= \mathbb{E}[\textrm{math score} | \text{small}_i = 1] - \mathbb{E}[\textrm{math score} | \text{small}_i = 0] \\ &= b_0 + \delta - b_0 \\ &= \delta \end{align}$

--

Já sabíamos disso, mas agora entendemos por que isso é verdade `r emo::ji("v")`

---

class:inverse

# Tarefa: Sua Vez!


Execute o código a seguir para filtrar o conjunto de dados para manter apenas os alunos da primeira série e os grupos de turmas pequenas e regulares:

```{r, eval = FALSE}
star_df_clean <- star_df %>%
    filter(grade == "1" & star %in% c("small", "regular"))
```

1. Calcule a pontuação média em matemática para ambos os grupos e a diferença entre os dois.

1. Crie uma variável binária `tratamento` igual a `VERDADEIRO` se o aluno estiver no grupo de tratamento (ou seja, turma pequena) e `FALSO` se no grupo de controle (ou seja, turma de tamanho normal). *Dica:* você pode criar a variável binária com `tratamento = (star == "small")`.

1. Faça a regressão da pontuação em matemática na variável simulada de tratamento. Os resultados estão de acordo com a questão 2?

1. Como você interpreta esses coeficientes?
---

# Deficiências dos RCTs

Os RCTs têm uma ***validade interna*** muito forte, ou seja, eles podem estabelecer vínculos causais de forma convincente.

No entanto, eles têm algumas deficiências:

   * RCTs são **caros**,
   * RCTs podem enfrentar alguns **problemas éticos**: alguns *tratamentos* simplesmente não podem ser administrados às pessoas,
   * Os RCTs levam tempo e podemos ter **limitação de tempo**.

--

* **Interpretação** dos resultados:

   * ***Validade externa***: Resultados de um determinado RCT podem ser generalizados para outros contextos?
  
   * Desvendar os mecanismos que estão atuando pode ser difícil,
  
   * Aleatorização imperfeita, atrito, etc.
---


# O que vem depois?

* Portanto, se não podemos administrar um RCT, isso significa que temos que encontrar uma maneira de fazer inferência causal a partir de ***dados observacionais*** (em oposição a ***dados experimentais***).

--

2 casos amplos:

* ***seleção ocorre em características observáveis***: *regressão múltipla*

* ***seleção ocorre em características não observáveis***: múltiplas abordagens (e.g., *variáveis instrumentais*, *diferença em diferenças*, etc.)

---

<br>
<br>

.center[
```{r, echo = FALSE, out.width = "1000px"}
knitr::include_graphics("../../img/photos/correlation_funny.png")
```
]

---

# Leitura Recomendada

* CUNNINGHAM, Scott. Causal Inference: The Mixtape, New Haven: Yale University Press, 2021. URL: https://mixtape.scunning.com/

* ANGRIST, Joshua D.; PISCHKE, Jörn-Steffen. Mastering'metrics: The path from cause to effect. Princeton university press, 2014. URL: http://www.masteringmetrics.com/

* ANGRIST, Joshua D.; PISCHKE, Jörn-Steffen. Mostly harmless econometrics: An empiricist's companion. Princeton university press, 2009.

---
layout: false

class: title-slide-final, middle
background-image: url(../../img/logo/UdescEsag.jpeg)
background-size: 350px
background-position: 9% 19%

# ATÉ A PRÓXIMA AULA!




|                                                                                                            |                                   |
| :--------------------------------------------------------------------------------------------------------- | :-------------------------------- |
| <a href="https://github.com/rfbressan/econometria3_slides">.ScPored[<i class="fa fa-link fa-fw"></i>] | Slides |
| <a href="http://github.com/rfbressan">.ScPored[<i class="fa fa-github fa-fw"></i>]                          | @rfbressan                      |


.footnote[
[1]: Este slides foram baseados nas aulas de econometria da [SciencesPo Department of Economics](https://github.com/ScPoEcon/ScPoEconometrics-Slides)
]
---

layout: false
class: title-slide-section-red, middle

# Appendix

---

layout: true

<div class="my-footer"><img src="../img/logo/ScPo-shield.png" style="height: 60px;"/></div> 

---

name: attandatu

# Average Treatment on the Treated and on the Untreated

Other ***conditional*** average treatment effects may be of interest:

.pull-left[
**A**verage **T**reatment on the **T**reated (***ATT***)

\begin{align}
 ATT &= \mathop{\mathbb{E}}(\delta_i | D_i = 1) \\
     &= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0 | D_i = 1) \\
     &= \mathop{\mathbb{E}}(Y_i^1 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 1)
\end{align}

The ATT measures the ***average treatment effect conditional on being in the treatment group***.

*Example:* the effect of participating in a training program (*treatment*) for those who participated (*treatment group*).
]

.pull-right[
**A**verage **T**reatment on the **U**ntreated (***ATU***)

\begin{align}
 ATU &= \mathop{\mathbb{E}}(\delta_i | D_i = 0) \\
     &= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0 | D_i = 0) \\
     &= \mathop{\mathbb{E}}(Y_i^1 | D_i = 0) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)
\end{align}

The ATU measures the ***average treatment effect conditional on being in the control group***.

*Example:* the effect of attending a private school (*treatment*) for students from a public school (*control group*).
]

*Note:* In the majority of cases, ATE $\neq$ ATT $\neq$ ATU! <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> [*back*](#ate)

---

name: naive_comp_extended

# Problems with Naive Comparisons

Let's now relax the assumption that the treatment effect is constant among all individuals.

After [some tedious calculations](https://mixtape.scunning.com/potential-outcomes.html#simple-difference-in-means-decomposition) that we skip, the SDO can now be decomposed as: 

\begin{align}
  SDO &= ATE + \underbrace{\mathop{\mathbb{E}}(Y_i^0 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)}_\text{Selection bias} \\
  & \quad \quad  \quad \quad + \underbrace{(1-\pi)(ATT - ATU)}_\text{Heterogenous treatment effect bias}
\end{align}

where $1 - \pi$ denotes the share of people in the control group.

So there is a novel source of bias that comes from the potential ***heterogeneity in the individual treatment effect*** $\delta_i$.

* ***Selection bias***: those who attend university are likely to have higher baseline cognitive skills (regardless of whether they actually attend college).
* ***Heterogeneous treatment effect bias***: those who attend university may improve their cognitive skills more at university because they are more motivated. <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> [back](#naive_comp)